{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spotify API to get top tracks of an artist using the Spotipy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # load environment variables\n",
    "\n",
    "client_id = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
    "\n",
    "# spotipy setup\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and expand data from million song subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "million_songs_df = pd.read_csv('../data/clean/million_songs_df.csv')\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "SLEEP_TIME = 30\n",
    "\n",
    "# get the last processed index from existing backup file\n",
    "backup_file = '../data/local/spotify_million_tracks.csv'\n",
    "if os.path.exists(backup_file):\n",
    "    processed_df = pd.read_csv(backup_file)\n",
    "    start_index = len(processed_df)\n",
    "    print(f'Resuming from index {start_index}')\n",
    "else:\n",
    "    start_index = 0\n",
    "    print('Starting new processing')\n",
    "\n",
    "# process in batches\n",
    "for start_idx in range(start_index, len(million_songs_df), BATCH_SIZE):\n",
    "    batch = million_songs_df.iloc[start_idx:start_idx + BATCH_SIZE]\n",
    "    tracks_data = []\n",
    "    \n",
    "    print(f'\\nProcessing batch {start_idx//BATCH_SIZE + 1} of {len(million_songs_df)//BATCH_SIZE + 1}')\n",
    "    print(f'Processing rows {start_idx} to {min(start_idx + BATCH_SIZE, len(million_songs_df))}')\n",
    "    \n",
    "    for i, row in batch.iterrows():\n",
    "        try:\n",
    "            # search track\n",
    "            results = sp.search(q=f'track:{row[\"song_title\"]} artist:{row[\"artist\"]}', type='track', limit=1)\n",
    "            \n",
    "            if results['tracks']['items']:\n",
    "                track = results['tracks']['items'][0]\n",
    "                \n",
    "                # get genres\n",
    "                artist_id = track['artists'][0]['id']\n",
    "                artist_info = sp.artist(artist_id)\n",
    "                genres = artist_info['genres']\n",
    "                \n",
    "                tracks_data.append({\n",
    "                    'original_title': row['song_title'],\n",
    "                    'original_artist': row['artist'],\n",
    "                    'spotify_title': track['name'],\n",
    "                    'spotify_artist': track['artists'][0]['name'],\n",
    "                    'album': track['album']['name'],\n",
    "                    'release_date': track['album']['release_date'],\n",
    "                    'popularity': track['popularity'],\n",
    "                    'duration_ms': track['duration_ms'],\n",
    "                    'explicit': track['explicit'],\n",
    "                    'album_cover': track['album']['images'][0]['url'] if track['album']['images'] else None,\n",
    "                    'genres': genres if genres else None\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'Error processing track {row[\"song_title\"]}: {str(e)}')\n",
    "            continue\n",
    "    \n",
    "    # save batch results\n",
    "    if tracks_data:\n",
    "        temp_df = pd.DataFrame(tracks_data)\n",
    "        temp_df.to_csv(backup_file, \n",
    "                      mode='a', \n",
    "                      header=not os.path.exists(backup_file), \n",
    "                      index=False)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "        print(f'Batch completed at {timestamp}')\n",
    "        print(f'Processed {len(tracks_data)} tracks in this batch')\n",
    "        print(f'Total tracks processed: {start_idx + len(tracks_data)}')\n",
    "        print(f'Last track processed: {row[\"song_title\"]}')\n",
    "        print(f'Last track genres: {genres if genres else \"No genres found\"}')\n",
    "        \n",
    "        if start_idx + BATCH_SIZE < len(million_songs_df):  # don't sleep after the last batch\n",
    "            print(f'Sleeping for {SLEEP_TIME} seconds...')\n",
    "            print('-' * 50)\n",
    "            time.sleep(SLEEP_TIME)\n",
    "\n",
    "print(f'\\nAll batches processed!')\n",
    "print(f'Final total tracks processed: {start_idx + len(tracks_data)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
