{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spotify API to get top tracks of an artist using spotipy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from dotenv import load_dotenv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # load environment variables\n",
    "\n",
    "client_id = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
    "\n",
    "# spotipy setup\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with Led Zeppelin's URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lz_uri = 'spotify:artist:36QJpDe2go2KgaRleHCDTp'\n",
    "# results = sp.artist_top_tracks(lz_uri)\n",
    "\n",
    "# for track in results['tracks'][:10]:\n",
    "#     print('track    : ' + track['name'])\n",
    "#     print('cover art: ' + track['album']['images'][0]['url'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres = ['pop', 'rock', 'hip-hop', 'classical', 'jazz', 'electronic', 'metal', 'country'] # genres to randomly sample from\n",
    "\n",
    "# columns = ['track_name', 'artist', 'album', 'genres', 'popularity', 'explicit', 'cover_url'] # df columns\n",
    "\n",
    "# data = []\n",
    "\n",
    "# backup_file = 'spotify_tracks_backup.csv' # backup file path\n",
    "\n",
    "# # fetch and store data\n",
    "# def fetch_tracks_from_genre(genre, limit=25, market='US'):\n",
    "#     try:\n",
    "#         results = sp.search(\n",
    "#             q=f'genre:{genre}',  # search for tracks in a random genre\n",
    "#             type='track',\n",
    "#             limit=limit,          # limit the number of results\n",
    "#             market=market\n",
    "#         )\n",
    "#         tracks = results['tracks']['items']\n",
    "        \n",
    "#         for track in tracks:\n",
    "#             track_name = track['name']\n",
    "#             artist_names = ', '.join([artist['name'] for artist in track['artists']])\n",
    "#             album_name = track['album']['name']\n",
    "#             track_popularity = track['popularity']\n",
    "#             is_explicit = track['explicit']\n",
    "\n",
    "#             # get genres from the artist (additional API call)\n",
    "#             artist_genres = []\n",
    "#             for artist in track['artists']:\n",
    "#                 artist_info = sp.artist(artist['id'])\n",
    "#                 artist_genres.extend(artist_info['genres'])\n",
    "#             artist_genres = list(set(artist_genres))  # remove duplicates\n",
    "\n",
    "#             album_cover_url = track['album']['images'][1]['url']  # get album cover (index 1 is medium size\n",
    "\n",
    "#             # append data to track list\n",
    "#             data.append([track_name, artist_names, album_name, ', '.join(artist_genres), track_popularity, is_explicit, album_cover_url])\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f'Error fetching data for genre {genre}: {str(e)}')\n",
    "\n",
    "# num_tracks = 2000\n",
    "# batch_size = 25\n",
    "# num_batches = num_tracks // batch_size\n",
    "\n",
    "# for batch in range(num_batches):\n",
    "#     print(f'Fetching batch {batch + 1} of {num_batches}...')\n",
    "    \n",
    "#     random_genre = random.choice(genres) # fetch tracks from random genre\n",
    "#     fetch_tracks_from_genre(random_genre, limit=batch_size)\n",
    "    \n",
    "#     df_batch = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "#     # check if backup file exists\n",
    "#     if os.path.exists(backup_file):\n",
    "#         df_batch.to_csv(backup_file, mode='a', header=False, index=False) # append to existing file\n",
    "#     else:\n",
    "#         df_batch.to_csv(backup_file, mode='w', header=True, index=False) # write a new file\n",
    "    \n",
    "#     data = [] # clear data list for next batch\n",
    "    \n",
    "#     print(f'Pausing for 30 seconds... (Batch {batch + 1} of {num_batches})')\n",
    "#     time.sleep(30)\n",
    "\n",
    "# print('Data collection completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and expand data from million song subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spotipy\n",
    "# from spotipy.oauth2 import SpotifyClientCredentials\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Load credentials from .env\n",
    "# load_dotenv()\n",
    "# client_id = os.getenv('SPOTIFY_CLIENT_ID')\n",
    "# client_secret = os.getenv('SPOTIFY_CLIENT_SECRET')\n",
    "\n",
    "# # Initialize Spotify client\n",
    "# client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "# sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# # Load million songs dataset\n",
    "# million_songs_df = pd.read_csv('../data/clean/million_songs_df.csv')\n",
    "\n",
    "# # List to store track data\n",
    "# tracks_data = []\n",
    "# BATCH_SIZE = 25\n",
    "# SLEEP_TIME = 30\n",
    "\n",
    "# # Process songs in batches\n",
    "# for i, row in million_songs_df.iterrows():\n",
    "#     try:\n",
    "#         # Search for the track\n",
    "#         results = sp.search(q=f\"track:{row['song_title']} artist:{row['artist']}\", type='track', limit=1)\n",
    "        \n",
    "#         if results['tracks']['items']:\n",
    "#             track = results['tracks']['items'][0]\n",
    "            \n",
    "#             # Get artist genres\n",
    "#             artist_id = track['artists'][0]['id']\n",
    "#             artist_info = sp.artist(artist_id)\n",
    "#             genres = artist_info['genres']\n",
    "            \n",
    "#             tracks_data.append({\n",
    "#                 'original_title': row['song_title'],\n",
    "#                 'original_artist': row['artist'],\n",
    "#                 'spotify_title': track['name'],\n",
    "#                 'spotify_artist': track['artists'][0]['name'],\n",
    "#                 'album': track['album']['name'],\n",
    "#                 'release_date': track['album']['release_date'],\n",
    "#                 'popularity': track['popularity'],\n",
    "#                 'preview_url': track.get('preview_url'),\n",
    "#                 'duration_ms': track['duration_ms'],\n",
    "#                 'explicit': track['explicit'],\n",
    "#                 'spotify_url': track['external_urls']['spotify'],\n",
    "#                 'uri': track['uri'],\n",
    "#                 'genres': genres if genres else None\n",
    "#             })\n",
    "        \n",
    "#         # Save progress after every batch\n",
    "#         if len(tracks_data) % BATCH_SIZE == 0:\n",
    "#             # Generate timestamp for the backup file\n",
    "#             timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#             backup_file = f'../data/local/spotify_tracks_backup_{timestamp}.csv'\n",
    "            \n",
    "#             # Create DataFrame from current batch\n",
    "#             temp_df = pd.DataFrame(tracks_data)\n",
    "            \n",
    "#             # Save to CSV (append mode)\n",
    "#             temp_df.to_csv('../data/local/spotify_tracks_backup.csv', \n",
    "#                           mode='a', \n",
    "#                           header=not os.path.exists('../data/local/spotify_tracks_backup.csv'), \n",
    "#                           index=False)\n",
    "            \n",
    "#             # Save timestamped backup\n",
    "#             temp_df.to_csv(backup_file, index=False)\n",
    "            \n",
    "#             print(f\"Batch completed at {timestamp}\")\n",
    "#             print(f\"Processed {len(tracks_data)} tracks total\")\n",
    "#             print(f\"Last track processed: {row['song_title']}\")\n",
    "#             print(f\"Last track genres: {genres if genres else 'No genres found'}\")\n",
    "#             print(f\"Sleeping for {SLEEP_TIME} seconds...\")\n",
    "#             print(\"-\" * 50)\n",
    "            \n",
    "#             time.sleep(SLEEP_TIME)\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing track {row['song_title']}: {str(e)}\")\n",
    "#         continue\n",
    "\n",
    "# # Save any remaining tracks\n",
    "# if len(tracks_data) % BATCH_SIZE != 0:\n",
    "#     temp_df = pd.DataFrame(tracks_data)\n",
    "#     temp_df.to_csv('../data/local/spotify_tracks_backup.csv', \n",
    "#                    mode='a', \n",
    "#                    header=not os.path.exists('../data/local/spotify_tracks_backup.csv'), \n",
    "#                    index=False)\n",
    "\n",
    "# print(f\"\\nTotal tracks processed: {len(tracks_data)}\")\n",
    "# print(\"Columns in dataset:\")\n",
    "# print(temp_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with 10 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load million songs dataset (first 10 rows for testing)\n",
    "million_songs_df = pd.read_csv('../data/clean/million_songs_df.csv')\n",
    "\n",
    "# List to store track data\n",
    "tracks_data = []\n",
    "BATCH_SIZE = 25\n",
    "SLEEP_TIME = 30\n",
    "\n",
    "# Process only the first 10 rows for testing\n",
    "test_data = million_songs_df.head(10)  # Limit to 10 rows for testing\n",
    "\n",
    "# Process songs in batches\n",
    "for i, row in test_data.iterrows():\n",
    "    try:\n",
    "        # Search for the track\n",
    "        results = sp.search(q=f\"track:{row['song_title']} artist:{row['artist']}\", type='track', limit=1)\n",
    "        \n",
    "        if results['tracks']['items']:\n",
    "            track = results['tracks']['items'][0]\n",
    "            \n",
    "            # Get artist genres\n",
    "            artist_id = track['artists'][0]['id']\n",
    "            artist_info = sp.artist(artist_id)\n",
    "            genres = artist_info['genres']\n",
    "            \n",
    "            tracks_data.append({\n",
    "                'original_title': row['song_title'],\n",
    "                'original_artist': row['artist'],\n",
    "                'spotify_title': track['name'],\n",
    "                'spotify_artist': track['artists'][0]['name'],\n",
    "                'album': track['album']['name'],\n",
    "                'release_date': track['album']['release_date'],\n",
    "                'popularity': track['popularity'],\n",
    "                'preview_url': track.get('preview_url'),\n",
    "                'duration_ms': track['duration_ms'],\n",
    "                'explicit': track['explicit'],\n",
    "                'spotify_url': track['external_urls']['spotify'],\n",
    "                'uri': track['uri'],\n",
    "                'genres': genres if genres else None\n",
    "            })\n",
    "        \n",
    "        # Save progress after every batch\n",
    "        if len(tracks_data) % BATCH_SIZE == 0:\n",
    "            # Generate timestamp for the backup file\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            backup_file = f'../data/local/spotify_tracks_backup_{timestamp}.csv'\n",
    "            \n",
    "            # Create DataFrame from current batch\n",
    "            temp_df = pd.DataFrame(tracks_data)\n",
    "            \n",
    "            # Save to CSV (append mode)\n",
    "            temp_df.to_csv('../data/local/spotify_tracks_backup.csv', \n",
    "                          mode='a', \n",
    "                          header=not os.path.exists('../data/local/spotify_tracks_backup.csv'), \n",
    "                          index=False)\n",
    "            \n",
    "            # Save timestamped backup\n",
    "            temp_df.to_csv(backup_file, index=False)\n",
    "            \n",
    "            print(f\"Batch completed at {timestamp}\")\n",
    "            print(f\"Processed {len(tracks_data)} tracks total\")\n",
    "            print(f\"Last track processed: {row['song_title']}\")\n",
    "            print(f\"Last track genres: {genres if genres else 'No genres found'}\")\n",
    "            print(f\"Sleeping for {SLEEP_TIME} seconds...\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            time.sleep(SLEEP_TIME)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing track {row['song_title']}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Save any remaining tracks\n",
    "if len(tracks_data) % BATCH_SIZE != 0:\n",
    "    temp_df = pd.DataFrame(tracks_data)\n",
    "    temp_df.to_csv('../data/local/spotify_tracks_backup.csv', \n",
    "                   mode='a', \n",
    "                   header=not os.path.exists('../data/local/spotify_tracks_backup.csv'), \n",
    "                   index=False)\n",
    "\n",
    "print(f\"\\nTotal tracks processed: {len(tracks_data)}\")\n",
    "print(\"Columns in dataset:\")\n",
    "print(temp_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
